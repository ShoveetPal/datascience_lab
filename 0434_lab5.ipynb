{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejbakneFf3OM"
   },
   "source": [
    "# Comparing Two Groups: Parametric Tests\n",
    "Parametric Test\t: Distribution\tAssumes data follows a specific distribution (usually normal distributiosn).\n",
    "Non-Parametric Test: \tDoes not assume any specific distribution (distribution-free)\n",
    "\n",
    "Assume data follows a specific distribution (usually normal distribution)\n",
    "\n",
    "Hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mGWOKOMWzMON"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "import warnings\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EwwyfEH-zOt_"
   },
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style consistent with previous tutorials\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_Z0DG44zRnV",
    "outputId": "3160d26e-a31d-4e3c-ab38-a37d3e6a53c3"
   },
   "outputs": [],
   "source": [
    "# Load the UCI Heart Disease dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "                'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "heart_data = pd.read_csv(url, names=column_names, na_values='?')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the UCI Heart Disease dataset:\")\n",
    "print(heart_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rUHH_0aWzTS2",
    "outputId": "c2d24aea-1817-4277-8391-4ccad9bf8215"
   },
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"\\nDataset Information:\")\n",
    "heart_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jf4xy45szUnw",
    "outputId": "743f7d54-e33d-4364-cce8-9ac2f9fea0c4"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(heart_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RnhugeFXzV6I"
   },
   "outputs": [],
   "source": [
    "# Replace missing values with the median for numerical columns\n",
    "heart_data = heart_data.fillna(heart_data.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDX9Ovm1zXvd",
    "outputId": "99ab4949-72f7-46be-9cd2-2930cf10a92c"
   },
   "outputs": [],
   "source": [
    "# Convert target variable to binary (0 = no disease, 1 = disease)\n",
    "heart_data['target'] = heart_data['target'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Convert sex to categorical for better interpretability (0 = female, 1 = male)\n",
    "heart_data['sex'] = heart_data['sex'].map({0: 'Female', 1: 'Male'})\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistical Summary:\")\n",
    "print(heart_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHfDuAdBzZkG"
   },
   "source": [
    "# 1. Hypothesis Testing\n",
    "\n",
    "1. Null Hypothesis (H₀):\n",
    "   - Assumes no effect, no difference, or no relationship\n",
    "   - The 'status quo' or default position\n",
    "   - What we assume is true until evidence suggests otherwise\n",
    "\n",
    "2. Alternative Hypothesis (H₁):\n",
    "   - Proposes an effect, difference, or relationship exists\n",
    "   - What we're typically trying to demonstrate\n",
    "   - May be one-tailed (directional) or two-tailed (non-directional)\n",
    "\n",
    "3. Test Statistic:\n",
    "   - Quantifies how different the observed data is from what we'd expect under H₀\n",
    "   - Examples: t-statistic, F-statistic, chi-square\n",
    "\n",
    "4. P-value:\n",
    "   - Probability of observing a result at least as extreme as the one obtained,\n",
    "     if the null hypothesis were true\n",
    "   - Small p-value (≤ α) → reject H₀\n",
    "   - Large p-value (> α) → fail to reject H₀\n",
    "   - Typical significance level (α) = 0.05\n",
    "\n",
    "5. Decision Rules:\n",
    "   - If p ≤ α, reject H₀ (statistically significant result)\n",
    "   - If p > α, fail to reject H₀ (not statistically significant)\n",
    "\n",
    "6. Common Misinterpretations of P-values:\n",
    "   - P-value is NOT the probability that H₀ is true\n",
    "   - P-value is NOT the probability that the finding is due to chance\n",
    "   - P-value does NOT indicate the size or importance of an effect\n",
    "   - Statistical significance does NOT imply practical significance\n",
    "\n",
    "7. Types of Errors:\n",
    "   - Type I Error (False Positive): Rejecting H₀ when it's actually true\n",
    "     Probability = α (significance level)\n",
    "   - Type II Error (False Negative): Failing to reject H₀ when it's actually false\n",
    "     Probability = β\n",
    "   - Power = 1 - β (Probability of correctly rejecting a false H₀)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY4MJp1-z-6E"
   },
   "source": [
    "# 2. P-value Visualization with Actual Data\n",
    "\n",
    "Plot disease and no disease distributions and visualize t-test from our data against theoretical t-distribution. Note that the theoretical distribution only depends on the degrees of freedom (n1+n2-2), in our case 301 (303-2) degrees. <p>\n",
    "We use scipy.stats.ttest_ind for our t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8nCVtUCC0K1q",
    "outputId": "51d4f580-8183-498a-defb-5726c5d721ef"
   },
   "outputs": [],
   "source": [
    "def visualize_t_test_with_actual_data(group1, group2, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Visualize t-test with both actual data distributions and theoretical t-distribution\n",
    "    using the actual heart disease dataset.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    group1 : array (or series) of First group's data (e.g., disease group)\n",
    "    group2 : array (or series) of Second group's data (e.g., no disease group)\n",
    "    \"\"\"\n",
    "    # Create a figure with 2 subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    # Plot 1: Actual distributions\n",
    "    sns.kdeplot(group1, ax=ax1, fill=True, color='blue', label='Disease Group')\n",
    "    sns.kdeplot(group2, ax=ax1, fill=True, color='green', label='No Disease Group')\n",
    "\n",
    "    # Add vertical lines for means\n",
    "    mean1, mean2 = group1.mean(), group2.mean()\n",
    "    ax1.axvline(mean1, color='blue', linestyle='--',\n",
    "               label=f'Disease Group Mean: {mean1:.2f}')\n",
    "    ax1.axvline(mean2, color='green', linestyle='--',\n",
    "               label=f'No Disease Group Mean: {mean2:.2f}')\n",
    "\n",
    "    # Add annotation for mean difference\n",
    "    mean_diff = mean1 - mean2\n",
    "    ax1.annotate(f'Mean Difference: {mean_diff:.2f}',\n",
    "                xy=((mean1 + mean2) / 2, 0.02),\n",
    "                xytext=((mean1 + mean2) / 2, 0.04),\n",
    "                ha='center',\n",
    "                arrowprops=dict(facecolor='black', shrink=0.05, width=1))\n",
    "\n",
    "    ax1.set_title(f'Actual Distributions by Heart Disease Status', fontsize=14)\n",
    "    ax1.set_xlabel('Value', fontsize=12)\n",
    "    ax1.set_ylabel('Density', fontsize=12)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Calculate t-statistic and p-value\n",
    "    t_stat, p_val = stats.ttest_ind(group1, group2)\n",
    "\n",
    "    # Calculate degrees of freedom\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    df = n1 + n2 - 2\n",
    "\n",
    "    # Plot 2: Theoretical t-distribution\n",
    "    x = np.linspace(-5, 5, 1000)\n",
    "    y = stats.t.pdf(x, df)\n",
    "\n",
    "    # Plot the t-distribution\n",
    "    ax2.plot(x, y, 'b-', lw=2, label=f't-distribution with {df} degrees of freedom')\n",
    "\n",
    "    # Fill the central region (non-rejection region)\n",
    "    t_crit = stats.t.ppf(1-alpha/2, df)\n",
    "    ax2.fill_between(x, y, where=(x >= -t_crit) & (x <= t_crit),\n",
    "                    color='gray', alpha=0.5,\n",
    "                    label=f'Non-rejection region (p > {alpha})')\n",
    "\n",
    "    # Fill the rejection regions\n",
    "    ax2.fill_between(x, y, where=(x <= -t_crit) | (x >= t_crit),\n",
    "                    color='lightgray', alpha=0.3,\n",
    "                    label=f'Critical region (p < {alpha})')\n",
    "\n",
    "    # Fill the observed p-value region\n",
    "    ax2.fill_between(x, y, where=(x <= -abs(t_stat)) | (x >= abs(t_stat)),\n",
    "                    color='red', alpha=0.4,\n",
    "                    label=f'p-value region: {p_val:.6f}')\n",
    "\n",
    "    # Add vertical lines for observed t-statistic\n",
    "    ax2.axvline(t_stat, color='r', linestyle='--', lw=2,\n",
    "                label=f'Observed t-statistic: {t_stat:.4f}')\n",
    "    ax2.axvline(-t_stat, color='r', linestyle='--', lw=2)\n",
    "\n",
    "    # Add critical value lines\n",
    "    ax2.axvline(t_crit, color='black', linestyle=':', lw=1.5,\n",
    "                label=f'Critical value: ±{t_crit:.4f}')\n",
    "    ax2.axvline(-t_crit, color='black', linestyle=':', lw=1.5)\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax2.set_title(\"T-Distribution with Observed T-Statistic\", fontsize=14)\n",
    "    ax2.set_xlabel('t-value', fontsize=12)\n",
    "    ax2.set_ylabel('Probability Density', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(loc='best', fontsize=10)\n",
    "\n",
    "    # Connection between plots - show how the difference leads to the t-statistic\n",
    "    arrow_props = dict(facecolor='black', width=1.5, headwidth=8)\n",
    "    fig.text(0.5, 0.5, \"The difference in means\\nis standardized to get\\nthe t-statistic\",\n",
    "             ha='center', va='center', fontsize=12,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"black\", lw=1))\n",
    "\n",
    "    # Add formula for t-statistic in a simpler format\n",
    "    std1, std2 = group1.std(), group2.std()\n",
    "    pooled_std = np.sqrt(((n1-1)*std1**2 + (n2-1)*std2**2) / (n1+n2-2))\n",
    "    std_error = pooled_std * np.sqrt(1/n1 + 1/n2)\n",
    "\n",
    "    # Add the formula as regular text instead of LaTeX\n",
    "    formula_text = (f\"t-statistic formula:\\n\"\n",
    "                   f\"t = (Mean1 - Mean2) / StandardError\\n\"\n",
    "                   f\"t = ({mean1:.2f} - {mean2:.2f}) / {std_error:.2f}\\n\"\n",
    "                   f\"t = {t_stat:.4f}\")\n",
    "\n",
    "    fig.text(0.5, 0.45, formula_text, ha='center', fontsize=12,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=\"black\", lw=1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Detailed explanation\n",
    "    print(\"\\nExplanation of the t-test and visualizations:\")\n",
    "    print(f\"1. Top plot: Shows the actual distribution of values in both groups\")\n",
    "    print(f\"   - Group 1 mean: {mean1:.2f}\")\n",
    "    print(f\"   - Group 2 mean: {mean2:.2f}\")\n",
    "    print(f\"   - Mean difference: {mean_diff:.2f}\")\n",
    "\n",
    "    print(f\"\\n2. Bottom plot: Shows the theoretical t-distribution with {df} degrees of freedom\")\n",
    "    print(f\"   - The t-statistic of {t_stat:.4f} is calculated by standardizing the mean difference\")\n",
    "    print(f\"   - The formula divides the mean difference by the standard error ({std_error:.2f})\")\n",
    "    print(f\"   - The p-value of {p_val:.6f} is the probability of observing a t-statistic of\")\n",
    "    print(f\"     {abs(t_stat):.4f} or more extreme if there were no real difference between groups\")\n",
    "\n",
    "    if p_val < alpha:\n",
    "        print(f\"   - Since p-value ({p_val:.6f}) < {alpha}, we reject the null hypothesis\")\n",
    "        print(f\"   - Conclusion: There is a statistically significant difference between groups\")\n",
    "    else:\n",
    "        print(f\"   - Since p-value ({p_val:.6f}) > {alpha}, we fail to reject the null hypothesis\")\n",
    "        print(f\"   - Conclusion: There is not enough evidence to claim a significant difference\")\n",
    "\n",
    "    print(f\"\\n3. Key concept: The t-distribution shape depends only on the degrees of freedom ({df}),\")\n",
    "    print(f\"   not on the specific values in our dataset\")\n",
    "\n",
    "    return t_stat, p_val, df\n",
    "\n",
    "# Use the t-test visualization with actual age data by heart disease status\n",
    "print(\"Example with Age: Comparing age between patients with and without heart disease\")\n",
    "disease_group = heart_data[heart_data['target'] == 1]['age']\n",
    "no_disease_group = heart_data[heart_data['target'] == 0]['age']\n",
    "visualize_t_test_with_actual_data(disease_group, no_disease_group)\n",
    "\n",
    "# Use the t-test visualization with cholesterol data\n",
    "print(\"\\nExample with Cholesterol: Comparing cholesterol between patients with and without heart disease\")\n",
    "disease_group_chol = heart_data[heart_data['target'] == 1]['chol']\n",
    "no_disease_group_chol = heart_data[heart_data['target'] == 0]['chol']\n",
    "visualize_t_test_with_actual_data(disease_group_chol, no_disease_group_chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TAUounT192m"
   },
   "source": [
    "# 3. Independent t-test\n",
    "\n",
    "For our dataset, compare variables (like cholesterol or age) between two groups (people with vs. without heart disease).\n",
    "\n",
    "**Check if the data meets the assumptions for a t-test:**\n",
    "\n",
    "Whether each group’s data is normally distributed.\n",
    "\n",
    "Whether the two groups have equal variances.\n",
    "\n",
    "**Choose the appropriate t-test:**\n",
    "\n",
    "Regular t-test if variances are equal.\n",
    "\n",
    "Welch’s t-test if variances are not equal.\n",
    "\n",
    "Perform the t-test to see if there is a statistically significant difference in the mean values of the two groups.\n",
    "\n",
    "Calculate and interpret the effect size (Cohen's d) to understand how big the difference is, not just whether it's significant.\n",
    "\n",
    "Estimate the statistical power, i.e., the likelihood of correctly detecting a true difference.\n",
    "\n",
    "If the power is low, it warns you and suggests how many samples you'd need per group for reliable results.\n",
    "\n",
    "**Generate four types of plots to visualize the comparison:**\n",
    "\n",
    "Box plot\n",
    "\n",
    "Violin plot\n",
    "\n",
    "Histograms\n",
    "\n",
    "Bar chart with confidence intervals and p-value annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q13LvkCl2Pyq",
    "outputId": "700e209f-affa-481c-f4de-62cc34e88d00"
   },
   "outputs": [],
   "source": [
    "def perform_independent_ttest(data, group_var, test_var, display_name=None, equal_var=True):\n",
    "    \"\"\"\n",
    "    Perform an independent samples t-test and visualize the results.\n",
    "    For example, compare age by target or cholesterol by target\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame - The dataset\n",
    "    group_var : The column name for the grouping variable (In our case, target - heart disease or no heart disease)\n",
    "    test_var : The column name for the test variable (what we're comparing). In our case age, or cholesterol, etc.\n",
    "    display_name : str, optional - A more readable name for the test variable (for plotting). e.g., Cholesterol (mg/dl)\n",
    "    equal_var : bool, default=True - Whether to assume equal variances\n",
    "    \"\"\"\n",
    "    if display_name is None:\n",
    "        display_name = test_var\n",
    "\n",
    "    # Split the data into two groups\n",
    "    group_values = data[group_var].unique()\n",
    "    if len(group_values) != 2:\n",
    "        print(f\"Error: {group_var} must have exactly 2 unique values for t-test.\")\n",
    "        return\n",
    "\n",
    "    group1 = data[data[group_var] == group_values[0]][test_var].dropna()\n",
    "    group2 = data[data[group_var] == group_values[1]][test_var].dropna()\n",
    "\n",
    "\n",
    "\n",
    "    # Check homogeneity of variance assumption\n",
    "    _, p_levene = stats.levene(group1, group2)\n",
    "    print(f\"\\nChecking homogeneity of variance assumption:\")\n",
    "    print(f\"  Levene's test p-value: {p_levene:.4f}\")\n",
    "    print(f\"  Variances are {'equal' if p_levene > 0.05 else 'not equal'}\")\n",
    "\n",
    "    # Decide whether to use equal variance assumption based on Levene's test\n",
    "    if p_levene < 0.05:\n",
    "        equal_var = False\n",
    "        print(\"  Using Welch's t-test (unequal variances)\")\n",
    "    else:\n",
    "        print(\"  Using Student's t-test (equal variances)\")\n",
    "\n",
    "    # Perform the t-test\n",
    "    t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=equal_var)\n",
    "\n",
    "    # Calculate descriptive statistics\n",
    "    mean1, std1 = group1.mean(), group1.std()\n",
    "    mean2, std2 = group2.mean(), group2.std()\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    # Calculate effect size (Cohen's d)\n",
    "    if equal_var:\n",
    "        # Pooled standard deviation\n",
    "        s_pooled = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "        d = (mean2 - mean1) / s_pooled\n",
    "    else:\n",
    "        # For Welch's t-test, use average standard deviation\n",
    "        d = (mean2 - mean1) / np.sqrt((std1**2 + std2**2) / 2)\n",
    "\n",
    "    # Interpret effect size\n",
    "    if abs(d) < 0.2:\n",
    "        d_interpretation = \"negligible\"\n",
    "    elif abs(d) < 0.5:\n",
    "        d_interpretation = \"small\"\n",
    "    elif abs(d) < 0.8:\n",
    "        d_interpretation = \"medium\"\n",
    "    else:\n",
    "        d_interpretation = \"large\"\n",
    "\n",
    "    # Calculate confidence interval for the mean difference\n",
    "    if equal_var:\n",
    "        dof = n1 + n2 - 2\n",
    "    else:\n",
    "        # Calculate Welch-Satterthwaite equation for degrees of freedom\n",
    "        # This is the correct way to calculate df for Welch's t-test\n",
    "        dof = ((std1**2/n1 + std2**2/n2)**2) / \\\n",
    "              ((std1**4/(n1**2*(n1-1)) + std2**4/(n2**2*(n2-1))))\n",
    "\n",
    "    mean_diff = mean2 - mean1\n",
    "\n",
    "    # Standard error of the difference between means\n",
    "    if equal_var:\n",
    "        se_diff = s_pooled * np.sqrt(1/n1 + 1/n2)\n",
    "    else:\n",
    "        se_diff = np.sqrt(std1**2/n1 + std2**2/n2)\n",
    "\n",
    "    # Calculate 95% confidence interval\n",
    "    t_crit = stats.t.ppf(0.975, dof)  # 95% confidence interval\n",
    "    ci_lower = mean_diff - t_crit * se_diff\n",
    "    ci_upper = mean_diff + t_crit * se_diff\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nIndependent Samples T-Test Results:\")\n",
    "    print(f\"  Comparing {display_name} between {group_values[0]} and {group_values[1]}\")\n",
    "    print(f\"  {group_values[0]}: Mean = {mean1:.2f}, SD = {std1:.2f}, n = {n1}\")\n",
    "    print(f\"  {group_values[1]}: Mean = {mean2:.2f}, SD = {std2:.2f}, n = {n2}\")\n",
    "    print(f\"  Mean difference: {mean_diff:.2f}, 95% CI [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "    print(f\"  t({dof:.1f}) = {t_stat:.4f}, p = {p_value:.4f}\")\n",
    "    print(f\"  Cohen's d = {d:.4f} ({d_interpretation} effect)\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(f\"  Result: Statistically significant difference in {display_name} between groups\")\n",
    "    else:\n",
    "        print(f\"  Result: No statistically significant difference in {display_name} between groups\")\n",
    "\n",
    "    # Calculate power\n",
    "    power_analysis = TTestIndPower()\n",
    "    power = power_analysis.power(effect_size=abs(d), nobs1=n1, alpha=0.05, ratio=n2/n1)\n",
    "    print(f\"  Statistical power: {power:.4f}\")\n",
    "\n",
    "    if power < 0.8:\n",
    "        print(f\"  Warning: Low statistical power. Sample size might be too small to detect the effect.\")\n",
    "        # Calculate required sample size for 80% power\n",
    "        required_n = power_analysis.solve_power(effect_size=abs(d), power=0.8, alpha=0.05, ratio=1)\n",
    "        print(f\"  Required sample size per group for 80% power: {int(np.ceil(required_n))}\")\n",
    "\n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # 1. Box plots\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.boxplot(x=group_var, y=test_var, data=data)\n",
    "    plt.title(f'Box Plot of {display_name} by {group_var}')\n",
    "    plt.ylabel(display_name)\n",
    "\n",
    "    # 2. Violin plots\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.violinplot(x=group_var, y=test_var, data=data, inner='quartile')\n",
    "    plt.title(f'Violin Plot of {display_name} by {group_var}')\n",
    "    plt.ylabel(display_name)\n",
    "\n",
    "    # 3. Histogram for each group\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.histplot(group1, color='blue', alpha=0.5, label=group_values[0], kde=True)\n",
    "    sns.histplot(group2, color='orange', alpha=0.5, label=group_values[1], kde=True)\n",
    "    plt.title(f'Distribution of {display_name} by {group_var}')\n",
    "    plt.xlabel(display_name)\n",
    "    plt.legend()\n",
    "\n",
    "    # 4. Bar plot with error bars\n",
    "    plt.subplot(2, 2, 4)\n",
    "\n",
    "    # Create data for bar plot\n",
    "    bar_data = pd.DataFrame({\n",
    "        'Group': [group_values[0], group_values[1]],\n",
    "        'Mean': [mean1, mean2],\n",
    "        'SD': [std1, std2],\n",
    "        'SE': [std1/np.sqrt(n1), std2/np.sqrt(n2)],\n",
    "        'CI_lower': [mean1 - t_crit * std1/np.sqrt(n1), mean2 - t_crit * std2/np.sqrt(n2)],\n",
    "        'CI_upper': [mean1 + t_crit * std1/np.sqrt(n1), mean2 + t_crit * std2/np.sqrt(n2)]\n",
    "    })\n",
    "\n",
    "    # Plot bars\n",
    "    sns.barplot(x='Group', y='Mean', data=bar_data, palette='viridis')\n",
    "\n",
    "    # Add error bars (95% confidence intervals)\n",
    "    plt.errorbar(x=range(len(bar_data)), y=bar_data['Mean'],\n",
    "                yerr=[(bar_data['Mean'] - bar_data['CI_lower']).values,\n",
    "                     (bar_data['CI_upper'] - bar_data['Mean']).values],\n",
    "                fmt='none', c='black', capsize=5)\n",
    "\n",
    "    plt.title(f'Mean {display_name} with 95% CI by {group_var}')\n",
    "    plt.ylabel(f'Mean {display_name}')\n",
    "\n",
    "    # Add significance annotation if appropriate\n",
    "    if p_value < 0.05:\n",
    "        max_y = max(bar_data['CI_upper']) * 1.1\n",
    "        plt.plot([0, 0, 1, 1], [max_y, max_y + 0.05*max_y, max_y + 0.05*max_y, max_y], 'k-')\n",
    "        plt.text(0.5, max_y + 0.05*max_y, f'p = {p_value:.4f}', ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Independent Samples T-Test: {display_name} by {group_var}', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "    # Return the results for further analysis if needed\n",
    "    return {\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'cohens_d': d,\n",
    "        'mean_difference': mean_diff,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'power': power\n",
    "    }\n",
    "\n",
    "# Perform independent t-test for age by heart disease status\n",
    "print(\"Example 1: Comparing age between patients with and without heart disease\\n\")\n",
    "age_results = perform_independent_ttest(heart_data, 'target', 'age', 'Age (years)', equal_var=True)\n",
    "\n",
    "# Perform independent t-test for cholesterol by heart disease status\n",
    "print(\"\\nExample 2: Comparing cholesterol levels between patients with and without heart disease\\n\")\n",
    "chol_results = perform_independent_ttest(heart_data, 'target', 'chol', 'Cholesterol (mg/dl)', equal_var=True)\n",
    "\n",
    "# Perform independent t-test for maximum heart rate by heart disease status\n",
    "print(\"\\nExample 3: Comparing maximum heart rate achieved between patients with and without heart disease\\n\")\n",
    "hr_results = perform_independent_ttest(heart_data, 'target', 'thalach', 'Maximum Heart Rate', equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O87y0W3q5ygh"
   },
   "source": [
    "# 4. Paired t-test\n",
    "\n",
    "Now let us look at how to perform a paired t-test. Since our heart disease dataset does not include \"before and after\" measurements for the same individuals, we will simulate data for demonstration.\n",
    "\n",
    "We’ll generate artificial blood pressure values before and after a treatment. The idea is to test whether there is a statistically significant change in blood pressure after the intervention.\n",
    "\n",
    "**Data Simulation:**\n",
    "We simulate “before treatment” blood pressure readings with a mean of 140 and standard deviation of 15. For the “after treatment” values, we simulate data with a slightly lower mean (135) and make it correlated to the “before” values to reflect paired observations (same individuals measured twice).\n",
    "\n",
    "**Normality Check:**\n",
    "Since the paired t-test assumes that the differences between the paired values are normally distributed, we check this assumption using the Shapiro-Wilk test.\n",
    "\n",
    "**Paired t-test:**\n",
    "If the assumption holds, we run the paired t-test, which compares the mean values before and after the intervention. This helps us determine if any observed difference is statistically significant.\n",
    "\n",
    "**Effect Size:**\n",
    "We also calculate Cohen’s d, a measure of how strong the difference is. This gives more insight than p-values alone by indicating whether the observed change is small, medium, or large.\n",
    "\n",
    "**Confidence Interval:**\n",
    "A 95% confidence interval is computed for the mean difference to show the range in which the true difference likely falls.\n",
    "\n",
    "**Statistical Power:**\n",
    "We estimate the power of the test — how likely it is to detect a true effect if it exists. If power is low (typically < 0.8), we calculate how many subjects would be needed to achieve reliable results.\n",
    "\n",
    "**Visualization:**\n",
    "Multiple plots help communicate the findings:\n",
    "\n",
    "A box plot to show the spread of values before and after.\n",
    "\n",
    "A paired line plot to visualize individual-level changes.\n",
    "\n",
    "A histogram of differences to assess the shape of the distribution.\n",
    "\n",
    "A bar plot with error bars to show means and 95% confidence intervals, along with significance markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wJ1NU_Xc6gIV",
    "outputId": "199c9571-dac4-4390-b9ee-11729947bf79"
   },
   "outputs": [],
   "source": [
    "def perform_paired_ttest(before_data, after_data, var_name, display_name=None):\n",
    "    \"\"\"\n",
    "    Perform a paired samples t-test and visualize the results.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    before_data : array-like\n",
    "        Data before treatment/intervention\n",
    "    after_data : array-like\n",
    "        Data after treatment/intervention\n",
    "    var_name : str\n",
    "        The name of the variable being tested\n",
    "    display_name : str, optional\n",
    "        A more readable name for the variable (for plotting)\n",
    "    \"\"\"\n",
    "    if display_name is None:\n",
    "        display_name = var_name\n",
    "\n",
    "    # Make sure data is of equal length\n",
    "    if len(before_data) != len(after_data):\n",
    "        print(\"Error: Before and after data must have the same length\")\n",
    "        return\n",
    "\n",
    "    # Calculate differences\n",
    "    diff = after_data - before_data\n",
    "\n",
    "    # Check normality of differences\n",
    "    _, p_shapiro = stats.shapiro(diff)\n",
    "    print(f\"Checking normality assumption for the differences in {var_name}:\")\n",
    "    print(f\"  Shapiro-Wilk test p-value: {p_shapiro:.4f}\")\n",
    "    print(f\"  Distribution of differences is {'normal' if p_shapiro > 0.05 else 'non-normal'}\")\n",
    "\n",
    "    # Perform the paired t-test\n",
    "    t_stat, p_value = stats.ttest_rel(before_data, after_data)\n",
    "\n",
    "    # Calculate descriptive statistics\n",
    "    mean_before, std_before = np.mean(before_data), np.std(before_data, ddof=1)\n",
    "    mean_after, std_after = np.mean(after_data), np.std(after_data, ddof=1)\n",
    "    mean_diff = mean_after - mean_before\n",
    "    std_diff = np.std(diff, ddof=1)\n",
    "    n = len(before_data)\n",
    "\n",
    "    # Calculate effect size (Cohen's d for paired samples)\n",
    "    d = mean_diff / std_diff\n",
    "\n",
    "    # Interpret effect size\n",
    "    if abs(d) < 0.2:\n",
    "        d_interpretation = \"negligible\"\n",
    "    elif abs(d) < 0.5:\n",
    "        d_interpretation = \"small\"\n",
    "    elif abs(d) < 0.8:\n",
    "        d_interpretation = \"medium\"\n",
    "    else:\n",
    "        d_interpretation = \"large\"\n",
    "\n",
    "    # Calculate 95% confidence interval for the mean difference\n",
    "    se_diff = std_diff / np.sqrt(n)\n",
    "    t_crit = stats.t.ppf(0.975, n-1)  # 95% confidence interval\n",
    "    ci_lower = mean_diff - t_crit * se_diff\n",
    "    ci_upper = mean_diff + t_crit * se_diff\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nPaired Samples T-Test Results:\")\n",
    "    print(f\"  Comparing {display_name} before and after\")\n",
    "    print(f\"  Before: Mean = {mean_before:.2f}, SD = {std_before:.2f}\")\n",
    "    print(f\"  After: Mean = {mean_after:.2f}, SD = {std_after:.2f}\")\n",
    "    print(f\"  Mean difference (After - Before): {mean_diff:.2f}, 95% CI [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "    print(f\"  t({n-1}) = {t_stat:.4f}, p = {p_value:.4f}\")\n",
    "    print(f\"  Cohen's d = {d:.4f} ({d_interpretation} effect)\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(f\"  Result: Statistically significant change in {display_name}\")\n",
    "    else:\n",
    "        print(f\"  Result: No statistically significant change in {display_name}\")\n",
    "\n",
    "    # Calculate power\n",
    "    power_analysis = TTestPower()\n",
    "    power = power_analysis.power(effect_size=abs(d), nobs=n, alpha=0.05)\n",
    "    print(f\"  Statistical power: {power:.4f}\")\n",
    "\n",
    "    if power < 0.8:\n",
    "        print(f\"  Warning: Low statistical power. Sample size might be too small to detect the effect.\")\n",
    "        # Calculate required sample size for 80% power\n",
    "        required_n = power_analysis.solve_power(effect_size=abs(d), power=0.8, alpha=0.05)\n",
    "        print(f\"  Required sample size for 80% power: {int(np.ceil(required_n))}\")\n",
    "\n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # 1. Box plots\n",
    "    plt.subplot(2, 2, 1)\n",
    "    box_data = pd.DataFrame({\n",
    "        'Before': before_data,\n",
    "        'After': after_data\n",
    "    })\n",
    "    sns.boxplot(data=box_data)\n",
    "    plt.title(f'Box Plot of {display_name} Before and After')\n",
    "    plt.ylabel(display_name)\n",
    "\n",
    "    # 2. Paired plot\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    for i in range(n):\n",
    "        plt.plot([1, 2], [before_data[i], after_data[i]], 'k-', alpha=0.3)\n",
    "\n",
    "    # Add mean points\n",
    "    plt.plot(1, mean_before, 'ro', markersize=10, label='Mean Before')\n",
    "    plt.plot(2, mean_after, 'bo', markersize=10, label='Mean After')\n",
    "\n",
    "    # Connect means\n",
    "    plt.plot([1, 2], [mean_before, mean_after], 'r--', linewidth=2)\n",
    "\n",
    "    plt.xticks([1, 2], ['Before', 'After'])\n",
    "    plt.title(f'Paired Changes in {display_name}')\n",
    "    plt.ylabel(display_name)\n",
    "    plt.legend()\n",
    "\n",
    "    # 3. Histogram of differences\n",
    "    plt.subplot(2, 2, 3)\n",
    "    sns.histplot(diff, kde=True)\n",
    "    plt.axvline(0, color='r', linestyle='--')\n",
    "    plt.title(f'Distribution of Differences in {display_name} (After - Before)')\n",
    "    plt.xlabel('Difference')\n",
    "\n",
    "    # 4. Bar plot with error bars\n",
    "    plt.subplot(2, 2, 4)\n",
    "\n",
    "    # Create data for bar plot\n",
    "    bar_data = pd.DataFrame({\n",
    "        'Group': ['Before', 'After'],\n",
    "        'Mean': [mean_before, mean_after],\n",
    "        'SD': [std_before, std_after],\n",
    "        'SE': [std_before/np.sqrt(n), std_after/np.sqrt(n)],\n",
    "        'CI_lower': [mean_before - t_crit * std_before/np.sqrt(n),\n",
    "                    mean_after - t_crit * std_after/np.sqrt(n)],\n",
    "        'CI_upper': [mean_before + t_crit * std_before/np.sqrt(n),\n",
    "                    mean_after + t_crit * std_after/np.sqrt(n)]\n",
    "    })\n",
    "\n",
    "    # Plot bars\n",
    "    sns.barplot(x='Group', y='Mean', data=bar_data, palette='viridis')\n",
    "\n",
    "    # Add error bars (95% confidence intervals)\n",
    "    plt.errorbar(x=range(len(bar_data)), y=bar_data['Mean'],\n",
    "                yerr=[(bar_data['Mean'] - bar_data['CI_lower']).values,\n",
    "                     (bar_data['CI_upper'] - bar_data['Mean']).values],\n",
    "                fmt='none', c='black', capsize=5)\n",
    "\n",
    "    plt.title(f'Mean {display_name} with 95% CI Before and After')\n",
    "    plt.ylabel(f'Mean {display_name}')\n",
    "\n",
    "    # Add significance annotation if appropriate\n",
    "    if p_value < 0.05:\n",
    "        max_y = max(bar_data['CI_upper']) * 1.1\n",
    "        plt.plot([0, 0, 1, 1], [max_y, max_y + 0.05*max_y, max_y + 0.05*max_y, max_y], 'k-')\n",
    "        plt.text(0.5, max_y + 0.05*max_y, f'p = {p_value:.4f}', ha='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Paired Samples T-Test: {display_name}', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "    # Return the results for further analysis if needed\n",
    "    return {\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'cohens_d': d,\n",
    "        'mean_difference': mean_diff,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'power': power\n",
    "    }\n",
    "\n",
    "# Since we don't have actual before/after data, let's simulate some blood pressure data\n",
    "# for demonstration purposes\n",
    "print(\"Example 4: Comparing blood pressure before and after treatment (simulated data)\")\n",
    "\n",
    "\"\"\"\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate before data with mean 140 and SD 15\n",
    "bp_before = np.random.normal(140, 15, 50)\n",
    "\n",
    "# Simulate after data with mean 135 and SD 12\n",
    "# We'll create correlated data to mimic paired observations\n",
    "correlation = 0.7\n",
    "bp_after = np.random.normal(135, 12, 50)\n",
    "bp_after = correlation * bp_before + (1 - correlation) * bp_after\n",
    "\"\"\"\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "num_patients = 100\n",
    "# Simulate before data with mean 140 and SD 15\n",
    "bp_before = np.random.normal(140, 15, num_patients)\n",
    "\n",
    "# Simulate a moderate treatment effect: decrease of ~5 mmHg on average\n",
    "true_effect = -3.5  # desired average decrease\n",
    "noise_sd = 20     # realistic post-treatment variation\n",
    "correlation = 0.4\n",
    "\n",
    "# Add noise correlated with the before values\n",
    "random_noise = np.random.normal(0, noise_sd, num_patients)\n",
    "bp_after = bp_before + true_effect + (1 - correlation) * random_noise\n",
    "\n",
    "# Run the paired t-test on the simulated blood pressure data\n",
    "bp_results = perform_paired_ttest(bp_before, bp_after, 'blood_pressure', 'Blood Pressure (mmHg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4jGKuygUr-6n",
    "outputId": "b0542190-12c3-4cd6-c11e-fafca5a43357"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5. Chi-Square Test\n",
    "# -------------------------\n",
    "\n",
    "print(\"\\n\\n--- CHI-SQUARE TEST FOR CATEGORICAL DATA ---\\n\")\n",
    "\n",
    "def visualize_chi_square_test_detailed(contingency_table, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Visualize chi-square test with both the contingency table and theoretical chi-square distribution\n",
    "    using a detailed approach with the actual heart disease dataset.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    contingency_table : pandas.DataFrame\n",
    "        2x2 contingency table of observed frequencies\n",
    "    alpha : float, default=0.05\n",
    "        Significance level\n",
    "    \"\"\"\n",
    "    # Calculate chi-square statistic and p-value\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table, correction=False)  #Can disable Yates' continuity correction.\n",
    "\n",
    "    # Create a figure with 2 subplots with more space\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14), gridspec_kw={'height_ratios': [1, 2]})\n",
    "\n",
    "    # Plot 1: Contingency table as a heatmap\n",
    "    sns.heatmap(contingency_table, annot=True, fmt='d', cmap='YlGnBu', ax=ax1)\n",
    "    ax1.set_title('Contingency Table: Sex vs Heart Disease', fontsize=14)\n",
    "    ax1.set_xlabel('Heart Disease Status (0=No, 1=Yes)', fontsize=12)\n",
    "    ax1.set_ylabel('Sex', fontsize=12)\n",
    "\n",
    "    # Calculate percentages within each sex\n",
    "    row_percentages = contingency_table.div(contingency_table.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Create percentage text strings\n",
    "    row_names = contingency_table.index\n",
    "\n",
    "    # Handle differently named indices if necessary\n",
    "    if 'Male' in contingency_table.index and 'Female' in contingency_table.index:\n",
    "        total_males = contingency_table.loc['Male'].sum()\n",
    "        total_females = contingency_table.loc['Female'].sum()\n",
    "        male_disease_pct = row_percentages.loc['Male', 1]\n",
    "        female_disease_pct = row_percentages.loc['Female', 1]\n",
    "\n",
    "        # Text box for contingency table explanation\n",
    "        explanation = (f\"Out of {total_males} males, {contingency_table.loc['Male', 1]} ({male_disease_pct:.1f}%) have heart disease\\n\"\n",
    "                      f\"Out of {total_females} females, {contingency_table.loc['Female', 1]} ({female_disease_pct:.1f}%) have heart disease\")\n",
    "    else:\n",
    "        # Generic version for any 2x2 table\n",
    "        row1, row2 = contingency_table.index[0], contingency_table.index[1]\n",
    "        total_row1 = contingency_table.loc[row1].sum()\n",
    "        total_row2 = contingency_table.loc[row2].sum()\n",
    "        row1_col1_pct = row_percentages.loc[row1, 1]\n",
    "        row2_col1_pct = row_percentages.loc[row2, 1]\n",
    "\n",
    "        explanation = (f\"Out of {total_row1} {row1}, {contingency_table.loc[row1, 1]} ({row1_col1_pct:.1f}%) have heart disease\\n\"\n",
    "                      f\"Out of {total_row2} {row2}, {contingency_table.loc[row2, 1]} ({row2_col1_pct:.1f}%) have heart disease\")\n",
    "\n",
    "    # Add text below the first subplot but above the second subplot\n",
    "    plt.figtext(0.5, 0.6, explanation, ha='center', va='center', fontsize=12,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=\"black\", lw=1))\n",
    "\n",
    "    # Plot 2: Chi-square distribution\n",
    "    x = np.linspace(0, 50, 1000)\n",
    "    y = stats.chi2.pdf(x, dof)\n",
    "\n",
    "    # Plot the chi-square distribution\n",
    "    ax2.plot(x, y, 'b-', lw=2, label=f'Chi-square distribution with {dof} degrees of freedom')\n",
    "\n",
    "    # Fill the non-rejection region\n",
    "    chi2_crit = stats.chi2.ppf(1-alpha, dof)\n",
    "    ax2.fill_between(x, y, where=(x <= chi2_crit), color='gray', alpha=0.5,\n",
    "                    label=f'Non-rejection region (p > {alpha})')\n",
    "\n",
    "    # Fill the rejection region\n",
    "    ax2.fill_between(x, y, where=(x >= chi2_crit), color='lightgray', alpha=0.3,\n",
    "                    label=f'Critical region (p < {alpha})')\n",
    "\n",
    "    # Fill the observed p-value region\n",
    "    ax2.fill_between(x, y, where=(x >= chi2), color='red', alpha=0.4,\n",
    "                   label=f'p-value region: {p:.6f}')\n",
    "\n",
    "    # Add vertical lines for observed chi-square statistic\n",
    "    ax2.axvline(chi2, color='r', linestyle='--', lw=2,\n",
    "               label=f'Observed chi-square: {chi2:.4f}')\n",
    "\n",
    "    # Add critical value line\n",
    "    ax2.axvline(chi2_crit, color='black', linestyle=':', lw=1.5,\n",
    "              label=f'Critical value: {chi2_crit:.4f}')\n",
    "\n",
    "    # Add labels and legend\n",
    "    ax2.set_title(\"Chi-Square Distribution with Observed Statistic\", fontsize=14)\n",
    "    ax2.set_xlabel('Chi-square value', fontsize=12)\n",
    "    ax2.set_ylabel('Probability Density', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "    # Add chi-square formula in a text box\n",
    "    chi_formula = (f\"Chi-square formula:\\nχ² = Σ [(Observed - Expected)² / Expected]\\nχ² = {chi2:.4f}\")\n",
    "\n",
    "    # Position the formula box\n",
    "    plt.figtext(0.5, 0.5, chi_formula, ha='center', va='center', fontsize=12,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=\"black\", lw=1))\n",
    "\n",
    "    # Explain degrees of freedom with a separate text box\n",
    "    dof_explanation = (f\"Degrees of freedom = (rows-1) × (columns-1) = ({len(contingency_table.index)}-1) × ({len(contingency_table.columns)}-1) = {dof}\")\n",
    "\n",
    "    # Position the degrees of freedom box\n",
    "    plt.figtext(0.5, 0.43, dof_explanation, ha='center', va='center', fontsize=12,\n",
    "               bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=\"black\", lw=1))\n",
    "\n",
    "    # Add more space between subplots and adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate expected values for explanation\n",
    "    expected_table = pd.DataFrame(expected,\n",
    "                                 index=contingency_table.index,\n",
    "                                 columns=contingency_table.columns)\n",
    "\n",
    "    # Print comprehensive explanation\n",
    "    print(\"\\nChi-Square Test Explanation:\")\n",
    "    print(\"- Null hypothesis (H0): There is no association between variables\")\n",
    "    print(\"- Alternative hypothesis (H1): There is an association between variables\")\n",
    "    print(\"\\nContingency Table (Observed Counts):\")\n",
    "    print(contingency_table)\n",
    "\n",
    "    print(\"\\nExpected Counts (if no association existed):\")\n",
    "    print(expected_table.round(2))\n",
    "\n",
    "    print(\"\\nRow Percentages (% within each row):\")\n",
    "    print(row_percentages.round(2))\n",
    "\n",
    "    print(\"\\nChi-square calculation compares observed vs. expected counts:\")\n",
    "    print(\"Chi-square formula: χ² = Σ [(Observed - Expected)² / Expected]\")\n",
    "\n",
    "    # Show calculation details\n",
    "    chi2_components = np.zeros(shape=expected.shape)\n",
    "    for i in range(expected.shape[0]):\n",
    "        for j in range(expected.shape[1]):\n",
    "            observed = contingency_table.iloc[i, j]\n",
    "            exp = expected[i, j]\n",
    "            chi2_components[i, j] = ((observed - exp) ** 2) / exp\n",
    "            print(f\"Cell [{contingency_table.index[i]}, {contingency_table.columns[j]}]: ({observed} - {exp:.1f})² / {exp:.1f} = {chi2_components[i, j]:.2f}\")\n",
    "\n",
    "    print(f\"Sum of all components: {np.sum(chi2_components):.4f}\")\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"- Chi-square statistic: {chi2:.4f}\")\n",
    "    print(f\"- Degrees of freedom: {dof}\")\n",
    "    print(f\"- p-value: {p:.6f}\")\n",
    "\n",
    "    if p < alpha:\n",
    "        print(f\"- Since p-value ({p:.6f}) < {alpha}, we reject the null hypothesis\")\n",
    "        print(f\"- Conclusion: There is a statistically significant association between variables\")\n",
    "    else:\n",
    "        print(f\"- Since p-value ({p:.6f}) > {alpha}, we fail to reject the null hypothesis\")\n",
    "        print(f\"- Conclusion: There is not enough evidence to claim a significant association\")\n",
    "\n",
    "    # Return the results\n",
    "    return chi2, p, dof\n",
    "\n",
    "# Perform chi-square test for sex and heart disease with detailed explanation\n",
    "print(\"Example: Testing association between sex and heart disease\")\n",
    "contingency_table = pd.crosstab(heart_data['sex'], heart_data['target'])\n",
    "visualize_chi_square_test_detailed(contingency_table)\n",
    "\n",
    "# Perform chi-square test for chest pain type and heart disease with detailed explanation\n",
    "print(\"\\nExample: Testing association between chest pain type and heart disease\")\n",
    "# Convert cp (chest pain type) to categorical with labels for better interpretation\n",
    "heart_data['cp_cat'] = heart_data['cp'].astype(int).map({\n",
    "    1: 'Typical Angina',\n",
    "    2: 'Atypical Angina',\n",
    "    3: 'Non-anginal Pain',\n",
    "    4: 'Asymptomatic'\n",
    "})\n",
    "cp_contingency_table = pd.crosstab(heart_data['cp_cat'], heart_data['target'])\n",
    "visualize_chi_square_test_detailed(cp_contingency_table)\n",
    "\n",
    "# -------------------------\n",
    "# 6. Effect Size and Power Analysis\n",
    "# -------------------------\n",
    "\n",
    "print(\"\\n\\n--- EFFECT SIZE AND POWER ANALYSIS ---\\n\")\n",
    "\n",
    "def demonstrate_power_analysis():\n",
    "    \"\"\"Demonstrate power analysis for different scenarios using actual effect sizes from our data.\"\"\"\n",
    "    print(\"Understanding Statistical Power and Sample Size:\")\n",
    "    print(\"\\nStatistical power is the probability of detecting an effect when it actually exists.\")\n",
    "    print(\"It depends on four factors:\")\n",
    "    print(\"1. Sample size (n)\")\n",
    "    print(\"2. Effect size (e.g., Cohen's d)\")\n",
    "    print(\"3. Significance level (α)\")\n",
    "    print(\"4. Statistical test used\")\n",
    "\n",
    "    # Get actual effect sizes from our tests\n",
    "    # For age comparison\n",
    "    disease_group = heart_data[heart_data['target'] == 1]['age']\n",
    "    no_disease_group = heart_data[heart_data['target'] == 0]['age']\n",
    "    n1, n2 = len(disease_group), len(no_disease_group)\n",
    "    mean1, mean2 = disease_group.mean(), no_disease_group.mean()\n",
    "    std1, std2 = disease_group.std(), no_disease_group.std()\n",
    "    pooled_std = np.sqrt(((n1-1)*std1**2 + (n2-1)*std2**2) / (n1+n2-2))\n",
    "    age_effect_size = abs(mean1 - mean2) / pooled_std\n",
    "\n",
    "    # For cholesterol comparison\n",
    "    disease_group_chol = heart_data[heart_data['target'] == 1]['chol']\n",
    "    no_disease_group_chol = heart_data[heart_data['target'] == 0]['chol']\n",
    "    n1_chol, n2_chol = len(disease_group_chol), len(no_disease_group_chol)\n",
    "    mean1_chol, mean2_chol = disease_group_chol.mean(), no_disease_group_chol.mean()\n",
    "    std1_chol, std2_chol = disease_group_chol.std(), no_disease_group_chol.std()\n",
    "    pooled_std_chol = np.sqrt(((n1_chol-1)*std1_chol**2 + (n2_chol-1)*std2_chol**2) / (n1_chol+n2_chol-2))\n",
    "    chol_effect_size = abs(mean1_chol - mean2_chol) / pooled_std_chol\n",
    "\n",
    "    print(\"\\nActual Effect Sizes from our Heart Disease Data:\")\n",
    "    print(f\"- Age comparison: Cohen's d = {age_effect_size:.4f}\")\n",
    "    print(f\"- Cholesterol comparison: Cohen's d = {chol_effect_size:.4f}\")\n",
    "\n",
    "    # Create a range of sample sizes\n",
    "    sample_sizes = np.arange(10, 200, 10)\n",
    "\n",
    "    # Create effect sizes to visualize\n",
    "    effect_sizes = [0.2, 0.5, 0.8]  # Small, medium, large benchmarks\n",
    "    effect_labels = ['Small (d=0.2)', 'Medium (d=0.5)', 'Large (d=0.8)']\n",
    "\n",
    "    # Add our actual effect sizes\n",
    "    effect_sizes.append(age_effect_size)\n",
    "    effect_labels.append(f'Age Effect (d={age_effect_size:.2f})')\n",
    "    effect_sizes.append(chol_effect_size)\n",
    "    effect_labels.append(f'Cholesterol Effect (d={chol_effect_size:.2f})')\n",
    "\n",
    "    # Initialize the power analysis object\n",
    "    power_analysis = TTestIndPower()\n",
    "\n",
    "    # Calculate power for each combination\n",
    "    power_curves = {}\n",
    "    for effect_size in effect_sizes:\n",
    "        power_curves[effect_size] = [power_analysis.power(effect_size, n, alpha=0.05)\n",
    "                                   for n in sample_sizes]\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # Plot power curves\n",
    "    colors = ['blue', 'green', 'red', 'purple', 'orange']\n",
    "    for i, effect_size in enumerate(effect_sizes):\n",
    "        plt.plot(sample_sizes, power_curves[effect_size],\n",
    "                label=effect_labels[i], linewidth=2, color=colors[i])\n",
    "\n",
    "    # Add a horizontal line at 80% power\n",
    "    plt.axhline(y=0.8, color='black', linestyle='--',\n",
    "               label='Conventional Power Threshold (80%)')\n",
    "\n",
    "    # Mark our actual sample size\n",
    "    actual_n = min(n1, n2)\n",
    "    plt.axvline(x=actual_n, color='gray', linestyle=':',\n",
    "               label=f'Our sample size (n={actual_n} per group)')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('Sample Size (per group)', fontsize=12)\n",
    "    plt.ylabel('Statistical Power (1-β)', fontsize=12)\n",
    "    plt.title('Statistical Power vs. Sample Size for Different Effect Sizes', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate our current power\n",
    "    age_power = power_analysis.power(effect_size=age_effect_size, nobs1=n1, alpha=0.05, ratio=n2/n1)\n",
    "    chol_power = power_analysis.power(effect_size=chol_effect_size, nobs1=n1_chol, alpha=0.05, ratio=n2_chol/n1_chol)\n",
    "\n",
    "    print(\"\\nPower Analysis for Our Current Study:\")\n",
    "    print(f\"- Age comparison: Power = {age_power:.4f} ({age_power*100:.1f}%)\")\n",
    "    if age_power < 0.8:\n",
    "        print(f\"  Warning: Power is below the conventional 80% threshold\")\n",
    "    else:\n",
    "        print(f\"  Good: Power exceeds the conventional 80% threshold\")\n",
    "\n",
    "    print(f\"- Cholesterol comparison: Power = {chol_power:.4f} ({chol_power*100:.1f}%)\")\n",
    "    if chol_power < 0.8:\n",
    "        print(f\"  Warning: Power is below the conventional 80% threshold\")\n",
    "    else:\n",
    "        print(f\"  Good: Power exceeds the conventional 80% threshold\")\n",
    "\n",
    "    # Calculate sample sizes required for 80% power\n",
    "    print(\"\\nRequired Sample Size (per group) for 80% Power (α=0.05):\")\n",
    "\n",
    "    for i, effect_size in enumerate(effect_sizes):\n",
    "        required_n = power_analysis.solve_power(effect_size=effect_size, power=0.8, alpha=0.05)\n",
    "        print(f\"  {effect_labels[i]}: {int(np.ceil(required_n))} participants per group\")\n",
    "\n",
    "    print(\"\\nTrade-offs in Power Analysis:\")\n",
    "    print(\"1. Increasing sample size → Increases power but requires more resources\")\n",
    "    print(\"2. Larger effect sizes → Easier to detect (higher power)\")\n",
    "    print(\"3. Increasing alpha level (e.g., from 0.05 to 0.10) → Increases power but also increases Type I error risk\")\n",
    "    print(\"4. More precise measurements → Reduces variability, increasing power\")\n",
    "\n",
    "    # Show the relationship between power, alpha, and Type I/II errors\n",
    "    print(\"\\nRelationship between Errors and Decision Thresholds:\")\n",
    "    print(\"  Type I Error (α): Probability of falsely rejecting a true null hypothesis\")\n",
    "    print(\"  Type II Error (β): Probability of falsely accepting a false null hypothesis\")\n",
    "    print(\"  Power (1-β): Probability of correctly rejecting a false null hypothesis\")\n",
    "\n",
    "    # Create visualization of Type I vs Type II errors\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Parameters for two normal distributions\n",
    "    mu1, sigma1 = 0, 1  # Null hypothesis distribution\n",
    "    mu2, sigma2 = 1, 1  # Alternative hypothesis distribution (effect size = 1)\n",
    "\n",
    "    # Generate the x-axis values\n",
    "    x = np.linspace(-4, 6, 1000)\n",
    "\n",
    "    # Generate the y-values for both distributions\n",
    "    y1 = stats.norm.pdf(x, mu1, sigma1)\n",
    "    y2 = stats.norm.pdf(x, mu2, sigma2)\n",
    "\n",
    "    # Plot both distributions\n",
    "    plt.plot(x, y1, 'b-', linewidth=2, label='Null Hypothesis (H₀)')\n",
    "    plt.plot(x, y2, 'r-', linewidth=2, label='Alternative Hypothesis (H₁)')\n",
    "\n",
    "    # Set the critical value (for alpha = 0.05)\n",
    "    crit_val = stats.norm.ppf(0.95, mu1, sigma1)\n",
    "\n",
    "    # Fill Type I error region\n",
    "    plt.fill_between(x, y1, where=(x >= crit_val), color='blue', alpha=0.3,\n",
    "                    label='Type I Error (α)')\n",
    "\n",
    "    # Fill Type II error region\n",
    "    plt.fill_between(x, y2, where=(x <= crit_val), color='red', alpha=0.3,\n",
    "                    label='Type II Error (β)')\n",
    "\n",
    "    # Fill power region\n",
    "    plt.fill_between(x, y2, where=(x >= crit_val), color='green', alpha=0.3,\n",
    "                    label='Power (1-β)')\n",
    "\n",
    "    # Add vertical line for critical value\n",
    "    plt.axvline(crit_val, color='black', linestyle='--',\n",
    "              label=f'Critical Value (α = 0.05)')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title('Visualization of Statistical Power, Type I and Type II Errors', fontsize=14)\n",
    "    plt.xlabel('Test Statistic Value', fontsize=12)\n",
    "    plt.ylabel('Probability Density', fontsize=12)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Decision matrix visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Define data\n",
    "    row_labels = ['Reject H₀', 'Fail to Reject H₀']\n",
    "    col_labels = ['H₀ is True', 'H₀ is False']\n",
    "\n",
    "    # Create cells\n",
    "    cell_text = [\n",
    "        ['Type I Error\\n(False Positive)\\np = α', 'Correct Decision\\n(True Positive)\\np = 1-β (Power)'],\n",
    "        ['Correct Decision\\n(True Negative)\\np = 1-α', 'Type II Error\\n(False Negative)\\np = β']\n",
    "    ]\n",
    "\n",
    "    # Create colors for cells\n",
    "    colors = [['#ffcccc', '#ccffcc'], ['#ccffcc', '#ffcccc']]\n",
    "\n",
    "    # Draw the table\n",
    "    table = ax.table(cellText=cell_text, rowLabels=row_labels, colLabels=col_labels,\n",
    "                    cellColours=colors, loc='center', cellLoc='center')\n",
    "\n",
    "    # Adjust table properties\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 3)  # Adjust row height\n",
    "\n",
    "    # Turn off axes\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add title\n",
    "    plt.suptitle('Statistical Decision Matrix', fontsize=16, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nKey Points about Effect Size and Power:\")\n",
    "    print(\"1. Statistical significance (p < .05) does not indicate practical significance\")\n",
    "    print(\"2. Effect size quantifies the magnitude of the difference or relationship\")\n",
    "    print(\"3. Larger sample sizes can detect smaller effects (but consider practical importance)\")\n",
    "    print(\"4. Low-powered studies may miss true effects or exaggerate effect sizes when significant\")\n",
    "    print(\"5. Good practice: Plan sample size based on the smallest effect size of practical importance\")\n",
    "\n",
    "# Demonstrate power analysis\n",
    "demonstrate_power_analysis()\n",
    "\n",
    "# -------------------------\n",
    "# 7. Conclusion and Key Takeaways\n",
    "# -------------------------\n",
    "\n",
    "print(\"\\n\\n--- CONCLUSION AND KEY TAKEAWAYS ---\\n\")\n",
    "\n",
    "print(\"Key Takeaways from Comparing Two Groups:\")\n",
    "print(\"\\n1. Hypothesis Testing Framework:\")\n",
    "print(\"   - Null hypothesis testing provides a systematic approach to evaluate group differences\")\n",
    "print(\"   - p-values indicate compatibility with the null hypothesis, not the probability it's true\")\n",
    "print(\"   - Statistical significance (p < .05) does not automatically imply practical importance\")\n",
    "\n",
    "print(\"\\n2. Independent vs. Paired Tests:\")\n",
    "print(\"   - Independent t-test: Use when comparing unrelated groups\")\n",
    "print(\"   - Paired t-test: Use when comparing related/matched samples\")\n",
    "print(\"   - Chi-square test: Use when comparing categorical variables\")\n",
    "\n",
    "print(\"\\n3. Effect Sizes Matter:\")\n",
    "print(\"   - Cohen's d (t-tests): Standardized mean difference (.2=small, .5=medium, .8=large)\")\n",
    "print(\"   - Cramer's V (chi-square): Association strength (interpretation depends on df)\")\n",
    "print(\"   - Report effect sizes alongside p-values for complete interpretation\")\n",
    "\n",
    "print(\"\\n4. Statistical Power:\")\n",
    "print(\"   - Power is the probability of detecting a true effect\")\n",
    "print(\"   - Depends on sample size, effect size, alpha level, and test type\")\n",
    "print(\"   - Low power increases risk of missing meaningful effects (Type II error)\")\n",
    "print(\"   - A priori power analysis helps determine adequate sample size\")\n",
    "\n",
    "print(\"\\n5. Assumption Checking:\")\n",
    "print(\"   - All parametric tests have assumptions that should be verified\")\n",
    "print(\"   - Common assumptions: normality, homogeneity of variance, independence\")\n",
    "print(\"   - When assumptions are violated, consider transformations or non-parametric alternatives\")\n",
    "\n",
    "print(\"\\n6. Complete Reporting:\")\n",
    "print(\"   - Test type, test statistic, df, p-value, effect size, and confidence intervals\")\n",
    "print(\"   - Group means/proportions and measures of variability\")\n",
    "print(\"   - Clear statement of findings in plain language\")\n",
    "print(\"   - Appropriate visualizations to support interpretation\")\n",
    "\n",
    "print(\"\\nNext tutorial preview: Comparing Two Groups: Non-parametric Tests\")\n",
    "print(\"We'll explore how to compare groups when parametric assumptions are not met\")\n",
    "print(\"and learn about non-parametric alternatives to t-tests and other parametric methods.\")\n",
    "print(\"Dataset: UCI Heart Disease\")\n",
    "\n",
    "# End of Tutorial 4 code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFVlQvHZkIh_"
   },
   "source": [
    "# T-Test and Z-Test Examples\n",
    "\n",
    "## T-Test (Small Sample, n < 30)\n",
    "\n",
    "# CSV file: t_test_data.csv\n",
    "# Employee, Salary\n",
    "# 1,52000\n",
    "# 2,48000\n",
    "# 3,50500\n",
    "# 4,53500\n",
    "# 5,51000\n",
    "# 6,49500\n",
    "# 7,54000\n",
    "# 8,50000\n",
    "# 9,52500\n",
    "# 10,51500\n",
    "\n",
    "# Questions for t-test:\n",
    "# - Two-tailed test: Test whether the average salary of employees differs from the industry standard of $50,000 at α = 0.05.\n",
    "# - One-tailed test: Test whether the average salary of employees is less than $50,000 at α = 0.05.\n",
    "# Note: Population standard deviation is unknown, so we use t-test.\n",
    "\n",
    "---\n",
    "\n",
    "## Z-Test (Large Sample, n ≥ 30)\n",
    "\n",
    "# CSV file: z_test_data.csv\n",
    "# Employee, Salary\n",
    "# 1,51000\n",
    "# 2,52000\n",
    "# 3,49500\n",
    "# 4,50500\n",
    "# 5,50000\n",
    "# 6,51500\n",
    "# 7,49000\n",
    "# 8,52500\n",
    "# 9,53000\n",
    "# 10,50000\n",
    "# 11,51000\n",
    "# 12,49500\n",
    "# 13,50500\n",
    "# 14,50000\n",
    "# 15,51500\n",
    "# 16,49000\n",
    "# 17,52500\n",
    "# 18,53000\n",
    "# 19,50000\n",
    "# 20,51000\n",
    "# 21,52000\n",
    "# 22,49500\n",
    "# 23,50500\n",
    "# 24,50000\n",
    "# 25,51500\n",
    "# 26,49000\n",
    "# 27,52500\n",
    "# 28,53000\n",
    "# 29,50000\n",
    "# 30,51000\n",
    "\n",
    "# Questions for Z-test:\n",
    "# - Two-tailed test: Test whether the average salary of employees differs from the industry standard of $50,000 at α = 0.05.\n",
    "# - One-tailed test: Test whether the average salary of employees is greater than $50,000 at α = 0.05.\n",
    "# Note: Population standard deviation is known (σ = $2,500), so we use Z-test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files 't_test_data.csv' and 'z_test_data.csv' created.\n",
      "\n",
      "--- T-Test Data (First 5 Rows) ---\n",
      "   Employee  Salary\n",
      "0         1   52000\n",
      "1         2   48000\n",
      "2         3   50500\n",
      "3         4   53500\n",
      "4         5   51000\n",
      "Sample size (n) = 10\n",
      "\n",
      "--- Z-Test Data (First 5 Rows) ---\n",
      "   Employee  Salary\n",
      "0         1   51000\n",
      "1         2   52000\n",
      "2         3   49500\n",
      "3         4   50500\n",
      "4         5   50000\n",
      "Sample size (n) = 30\n",
      "\n",
      "========================================\n",
      "\n",
      "--- T-Test (Small Sample, Population SD Unknown) ---\n",
      "Sample Mean (x_bar): 51250.00\n",
      "Hypothesized Mean (mu_0): 50000\n",
      "Significance Level (alpha): 0.05\n",
      "\n",
      "1. Two-tailed T-Test\n",
      "   H0: mean = 50,000 (Average salary is 50,000)\n",
      "   H1: mean != 50,000 (Average salary differs from 50,000)\n",
      "   T-statistic: 2.1429\n",
      "   P-value: 0.0607\n",
      "   Conclusion: Fail to reject H0. (p-value 0.0607 >= alpha 0.05)\n",
      "   There is not statistically significant evidence that the average salary differs from 50,000.\n",
      "\n",
      "2. One-tailed T-Test (Less Than)\n",
      "   H0: mean >= 50,000\n",
      "   H1: mean < 50,000 (Average salary is less than 50,000)\n",
      "   T-statistic: 2.1429\n",
      "   P-value: 0.9696\n",
      "   Conclusion: Fail to reject H0. (p-value 0.9696 >= alpha 0.05)\n",
      "   There is not statistically significant evidence that the average salary is less than 50,000.\n",
      "\n",
      "========================================\n",
      "\n",
      "--- Z-Test (Large Sample, Population SD Known) ---\n",
      "Sample Mean (x_bar): 50866.67\n",
      "Sample Size (n): 30\n",
      "Hypothesized Mean (mu_0): 50000\n",
      "Population Std Dev (sigma): 2500\n",
      "Significance Level (alpha): 0.05\n",
      "\n",
      "1. Two-tailed Z-Test\n",
      "   H0: mean = 50,000 (Average salary is 50,000)\n",
      "   H1: mean != 50,000 (Average salary differs from 50,000)\n",
      "   Standard Error (SE): 456.4355\n",
      "   Z-statistic: 1.8988\n",
      "   P-value: 0.0576\n",
      "   Conclusion: Fail to reject H0. (p-value 0.0576 >= alpha 0.05)\n",
      "   There is not statistically significant evidence that the average salary differs from 50,000.\n",
      "\n",
      "2. One-tailed Z-Test (Greater Than)\n",
      "   H0: mean <= 50,000\n",
      "   H1: mean > 50,000 (Average salary is greater than 50,000)\n",
      "   Z-statistic: 1.8988\n",
      "   P-value: 0.0288\n",
      "   Conclusion: Reject H0. (p-value 0.0288 < alpha 0.05)\n",
      "   There is statistically significant evidence that the average salary is greater than 50,000.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "import io\n",
    "import numpy as np \n",
    "\n",
    "t_test_csv_data = \"\"\"Employee,Salary\n",
    "1,52000\n",
    "2,48000\n",
    "3,50500\n",
    "4,53500\n",
    "5,51000\n",
    "6,49500\n",
    "7,54000\n",
    "8,50000\n",
    "9,52500\n",
    "10,51500\n",
    "\"\"\"\n",
    "with open(\"t_test_data.csv\", \"w\") as f:\n",
    "    f.write(t_test_csv_data)\n",
    "\n",
    "z_test_csv_data = \"\"\"Employee,Salary\n",
    "1,51000\n",
    "2,52000\n",
    "3,49500\n",
    "4,50500\n",
    "5,50000\n",
    "6,51500\n",
    "7,49000\n",
    "8,52500\n",
    "9,53000\n",
    "10,50000\n",
    "11,51000\n",
    "12,49500\n",
    "13,50500\n",
    "14,50000\n",
    "15,51500\n",
    "16,49000\n",
    "17,52500\n",
    "18,53000\n",
    "19,50000\n",
    "20,51000\n",
    "21,52000\n",
    "22,49500\n",
    "23,50500\n",
    "24,50000\n",
    "25,51500\n",
    "26,49000\n",
    "27,52500\n",
    "28,53000\n",
    "29,50000\n",
    "30,51000\n",
    "\"\"\"\n",
    "with open(\"z_test_data.csv\", \"w\") as f:\n",
    "    f.write(z_test_csv_data)\n",
    "\n",
    "print(\"CSV files 't_test_data.csv' and 'z_test_data.csv' created.\")\n",
    "\n",
    "try:\n",
    "    t_data = pd.read_csv(\"t_test_data.csv\")\n",
    "    z_data = pd.read_csv(\"z_test_data.csv\")\n",
    "\n",
    "    print(\"\\n--- T-Test Data (First 5 Rows) ---\")\n",
    "    print(t_data.head())\n",
    "    print(f\"Sample size (n) = {len(t_data)}\")\n",
    "    \n",
    "    print(\"\\n--- Z-Test Data (First 5 Rows) ---\")\n",
    "    print(z_data.head())\n",
    "    print(f\"Sample size (n) = {len(z_data)}\")\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "    print(\"--- T-Test (Small Sample, Population SD Unknown) ---\")\n",
    "    t_salaries = t_data['Salary']\n",
    "    hypothesized_mean_t = 50000\n",
    "    alpha_t = 0.05\n",
    "    sample_mean_t = t_salaries.mean()\n",
    "    \n",
    "    print(f\"Sample Mean (x_bar): {sample_mean_t:.2f}\")\n",
    "    print(f\"Hypothesized Mean (mu_0): {hypothesized_mean_t}\")\n",
    "    print(f\"Significance Level (alpha): {alpha_t}\")\n",
    "\n",
    "\n",
    "    print(\"\\n1. Two-tailed T-Test\")\n",
    "    print(\"   H0: mean = 50,000 (Average salary is 50,000)\")\n",
    "    print(\"   H1: mean != 50,000 (Average salary differs from 50,000)\")\n",
    "    \n",
    "    t_stat_two_tailed, p_value_two_tailed = stats.ttest_1samp(\n",
    "        t_salaries, \n",
    "        hypothesized_mean_t, \n",
    "        alternative='two-sided' # Specify two-sided\n",
    "    )\n",
    "    \n",
    "    print(f\"   T-statistic: {t_stat_two_tailed:.4f}\")\n",
    "    print(f\"   P-value: {p_value_two_tailed:.4f}\")\n",
    "    \n",
    "    if p_value_two_tailed < alpha_t:\n",
    "        print(f\"   Conclusion: Reject H0. (p-value {p_value_two_tailed:.4f} < alpha {alpha_t})\")\n",
    "        print(\"   There is statistically significant evidence that the average salary differs from 50,000.\")\n",
    "    else:\n",
    "        print(f\"   Conclusion: Fail to reject H0. (p-value {p_value_two_tailed:.4f} >= alpha {alpha_t})\")\n",
    "        print(\"   There is not statistically significant evidence that the average salary differs from 50,000.\")\n",
    "\n",
    "    print(\"\\n2. One-tailed T-Test (Less Than)\")\n",
    "    print(\"   H0: mean >= 50,000\")\n",
    "    print(\"   H1: mean < 50,000 (Average salary is less than 50,000)\")\n",
    "    \n",
    "    t_stat_one_tailed_less, p_value_one_tailed_less = stats.ttest_1samp(\n",
    "        t_salaries, \n",
    "        hypothesized_mean_t, \n",
    "        alternative='less' \n",
    "    )\n",
    "    \n",
    "    print(f\"   T-statistic: {t_stat_one_tailed_less:.4f}\")\n",
    "    print(f\"   P-value: {p_value_one_tailed_less:.4f}\")\n",
    "    \n",
    "\n",
    "    if p_value_one_tailed_less < alpha_t:\n",
    "        print(f\"   Conclusion: Reject H0. (p-value {p_value_one_tailed_less:.4f} < alpha {alpha_t})\")\n",
    "        print(\"   There is statistically significant evidence that the average salary is less than 50,000.\")\n",
    "    else:\n",
    "        print(f\"   Conclusion: Fail to reject H0. (p-value {p_value_one_tailed_less:.4f} >= alpha {alpha_t})\")\n",
    "        print(\"   There is not statistically significant evidence that the average salary is less than 50,000.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "    print(\"--- Z-Test (Large Sample, Population SD Known) ---\")\n",
    "    z_salaries = z_data['Salary']\n",
    "    hypothesized_mean_z = 50000\n",
    "    pop_std_dev = 2500  \n",
    "    alpha_z = 0.05\n",
    "    \n",
    "    n_z = len(z_salaries)\n",
    "    x_bar_z = z_salaries.mean()\n",
    "    \n",
    "    print(f\"Sample Mean (x_bar): {x_bar_z:.2f}\")\n",
    "    print(f\"Sample Size (n): {n_z}\")\n",
    "    print(f\"Hypothesized Mean (mu_0): {hypothesized_mean_z}\")\n",
    "    print(f\"Population Std Dev (sigma): {pop_std_dev}\")\n",
    "    print(f\"Significance Level (alpha): {alpha_z}\")\n",
    "\n",
    "\n",
    "    se_z = pop_std_dev / (n_z**0.5) \n",
    "    \n",
    "    print(\"\\n1. Two-tailed Z-Test\")\n",
    "    print(\"   H0: mean = 50,000 (Average salary is 50,000)\")\n",
    "    print(\"   H1: mean != 50,000 (Average salary differs from 50,000)\")\n",
    "\n",
    "    z_stat_two_tailed_manual = (x_bar_z - hypothesized_mean_z) / se_z\n",
    "    p_value_two_tailed_manual = 2 * (1 - stats.norm.cdf(abs(z_stat_two_tailed_manual)))\n",
    "    \n",
    "    print(f\"   Standard Error (SE): {se_z:.4f}\")\n",
    "    print(f\"   Z-statistic: {z_stat_two_tailed_manual:.4f}\")\n",
    "    print(f\"   P-value: {p_value_two_tailed_manual:.4f}\")\n",
    "\n",
    "    if p_value_two_tailed_manual < alpha_z:\n",
    "        print(f\"   Conclusion: Reject H0. (p-value {p_value_two_tailed_manual:.4f} < alpha {alpha_z})\")\n",
    "        print(\"   There is statistically significant evidence that the average salary differs from 50,000.\")\n",
    "    else:\n",
    "        print(f\"   Conclusion: Fail to reject H0. (p-value {p_value_two_tailed_manual:.4f} >= alpha {alpha_z})\")\n",
    "        print(\"   There is not statistically significant evidence that the average salary differs from 50,000.\")\n",
    "    print(\"\\n2. One-tailed Z-Test (Greater Than)\")\n",
    "    print(\"   H0: mean <= 50,000\")\n",
    "    print(\"   H1: mean > 50,000 (Average salary is greater than 50,000)\")\n",
    "\n",
    "    z_stat_one_tailed_greater_manual = z_stat_two_tailed_manual \n",
    "    p_value_one_tailed_greater_manual = 1 - stats.norm.cdf(z_stat_one_tailed_greater_manual)\n",
    "\n",
    "    print(f\"   Z-statistic: {z_stat_one_tailed_greater_manual:.4f}\")\n",
    "    print(f\"   P-value: {p_value_one_tailed_greater_manual:.4f}\")\n",
    "\n",
    "    if p_value_one_tailed_greater_manual < alpha_z:\n",
    "        print(f\"   Conclusion: Reject H0. (p-value {p_value_one_tailed_greater_manual:.4f} < alpha {alpha_z})\")\n",
    "        print(\"   There is statistically significant evidence that the average salary is greater than 50,000.\")\n",
    "    else:\n",
    "        print(f\"   Conclusion: Fail to reject H0. (p-value {p_value_one_tailed_greater_manual:.4f} >= alpha {alpha_z})\")\n",
    "        print(\"   There is not statistically significant evidence that the average salary is greater than 50,000.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: One of the CSV files was not found. {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
